{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Muselsl_EEG.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F9LwwGhDSqKb","executionInfo":{"status":"ok","timestamp":1613495267856,"user_tz":-330,"elapsed":94818,"user":{"displayName":"Srini Sriram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7y0thGEYPYKNwAFoAjrpt6mEJosxCscvoLAx1pg=s64","userId":"08361603766535905230"}},"outputId":"3f7643fa-c8b6-4bb6-a710-339f7c7def9e"},"source":["!pip3 install numpy\n","!pip3 install pandas\n","!pip3 install keras==2.3.1\n","!pip3 install tensorflow==2.1.0\n","!pip3 install fastai --upgrade\n","!pip3 install --user graphviz\n","!pip3 install torch"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.19.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.5)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.19.5)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Requirement already satisfied: keras==2.3.1 in /usr/local/lib/python3.6/dist-packages (2.3.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (3.13)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.1.2)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.15.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.4.1)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.19.5)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (2.10.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.0.8)\n","Collecting tensorflow==2.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n","\u001b[K     |████████████████████████████████| 421.8MB 38kB/s \n","\u001b[?25hCollecting tensorboard<2.2.0,>=2.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.9MB 48.6MB/s \n","\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.2)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.0)\n","Collecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.12.4)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.32.0)\n","Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n","\u001b[K     |████████████████████████████████| 450kB 52.2MB/s \n","\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.3.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.36.2)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n","Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.4.1)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.10.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.1)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.8.1)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.15.0)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.19.5)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.0.8)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.23.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.3.3)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.2)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (53.0.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.1)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.25.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (2.10.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.4.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.2.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.7)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.4.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=9b0749e4bbd9d254b38d08e62140e0355f82599197316fadbd61def8ec478d99\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built gast\n","\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","Installing collected packages: tensorboard, gast, tensorflow-estimator, tensorflow\n","  Found existing installation: tensorboard 2.4.1\n","    Uninstalling tensorboard-2.4.1:\n","      Successfully uninstalled tensorboard-2.4.1\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","  Found existing installation: tensorflow-estimator 2.4.0\n","    Uninstalling tensorflow-estimator-2.4.0:\n","      Successfully uninstalled tensorflow-estimator-2.4.0\n","  Found existing installation: tensorflow 2.4.1\n","    Uninstalling tensorflow-2.4.1:\n","      Successfully uninstalled tensorflow-2.4.1\n","Successfully installed gast-0.2.2 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n","Collecting fastai\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/09/36d4d472d0c953f5d931f4c415f715a909793e5d222af205f3e65c034da3/fastai-2.2.5-py3-none-any.whl (191kB)\n","\u001b[K     |████████████████████████████████| 194kB 7.6MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai) (3.2.2)\n","Requirement already satisfied, skipping upgrade: pip in /usr/local/lib/python3.6/dist-packages (from fastai) (19.3.1)\n","Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from fastai) (20.9)\n","Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from fastai) (1.4.1)\n","Requirement already satisfied, skipping upgrade: fastprogress>=0.2.4 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.0.0)\n","Requirement already satisfied, skipping upgrade: torch<1.8,>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.7.0+cu101)\n","Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from fastai) (0.22.2.post1)\n","Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai) (3.13)\n","Requirement already satisfied, skipping upgrade: torchvision<0.9,>=0.8 in /usr/local/lib/python3.6/dist-packages (from fastai) (0.8.1+cu101)\n","Requirement already satisfied, skipping upgrade: pillow>6.0.0 in /usr/local/lib/python3.6/dist-packages (from fastai) (7.0.0)\n","Collecting fastcore<1.4,>=1.3.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/98/60404e2817cff113a6ae4023bc1772e23179408fdf7857fa410551758dfe/fastcore-1.3.19-py3-none-any.whl (53kB)\n","\u001b[K     |████████████████████████████████| 61kB 6.4MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from fastai) (1.1.5)\n","Requirement already satisfied, skipping upgrade: spacy in /usr/local/lib/python3.6/dist-packages (from fastai) (2.2.4)\n","Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from fastai) (2.23.0)\n","Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (0.10.0)\n","Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (1.19.5)\n","Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (1.3.1)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.8.1)\n","Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.4.7)\n","Requirement already satisfied, skipping upgrade: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch<1.8,>=1.7.0->fastai) (0.8)\n","Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch<1.8,>=1.7.0->fastai) (3.7.4.3)\n","Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch<1.8,>=1.7.0->fastai) (0.16.0)\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->fastai) (1.0.0)\n","Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai) (2018.9)\n","Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (1.1.3)\n","Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (53.0.0)\n","Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (4.41.1)\n","Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (2.0.5)\n","Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (1.0.5)\n","Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (1.0.5)\n","Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (0.8.2)\n","Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (1.0.0)\n","Requirement already satisfied, skipping upgrade: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (7.4.0)\n","Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (3.0.5)\n","Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (0.4.1)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2020.12.5)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2.10)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (1.24.3)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (3.0.4)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->fastai) (1.15.0)\n","Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai) (3.4.0)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai) (3.4.0)\n","Installing collected packages: fastcore, fastai\n","  Found existing installation: fastai 1.0.61\n","    Uninstalling fastai-1.0.61:\n","      Successfully uninstalled fastai-1.0.61\n","Successfully installed fastai-2.2.5 fastcore-1.3.19\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (0.10.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZUFVVn2sNU6E","executionInfo":{"status":"ok","timestamp":1613495271745,"user_tz":-330,"elapsed":98701,"user":{"displayName":"Srini Sriram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7y0thGEYPYKNwAFoAjrpt6mEJosxCscvoLAx1pg=s64","userId":"08361603766535905230"}},"outputId":"4a4f05a0-c45d-4ba4-bc53-d28ac6ebe290"},"source":["import pandas as pd\n","import numpy as np\n","from keras.models import load_model\n","import fastai\n","import torch"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"-joZcZxXRgK0"},"source":["# Constants\n","channel_idx = 0\n","num_of_data = 178\n","existing = pd.DataFrame()\n","index = [\"X1\",\"X2\",\"X3\",\"X4\",\"X5\",\"X6\",\"X7\",\"X8\",\"X9\",\"X10\",\"X11\",\"X12\",\"X13\",\"X14\",\"X15\",\"X16\",\"X17\",\"X18\",\"X19\",\"X20\",\"X21\",\"X22\",\"X23\",\"X24\",\"X25\",\"X26\",\"X27\",\"X28\",\"X29\",\"X30\",\"X31\",\"X32\",\"X33\",\"X34\",\"X35\",\"X36\",\"X37\",\"X38\",\"X39\",\"X40\",\"X41\",\"X42\",\"X43\",\"X44\",\"X45\",\"X46\",\"X47\",\"X48\",\"X49\",\"X50\",\"X51\",\"X52\",\"X53\",\"X54\",\"X55\",\"X56\",\"X57\",\"X58\",\"X59\",\"X60\",\"X61\",\"X62\",\"X63\",\"X64\",\"X65\",\"X66\",\"X67\",\"X68\",\"X69\",\"X70\",\"X71\",\"X72\",\"X73\",\"X74\",\"X75\",\"X76\",\"X77\",\"X78\",\"X79\",\"X80\",\"X81\",\"X82\",\"X83\",\"X84\",\"X85\",\"X86\",\"X87\",\"X88\",\"X89\",\"X90\",\"X91\",\"X92\",\"X93\",\"X94\",\"X95\",\"X96\",\"X97\",\"X98\",\"X99\",\"X100\",\"X101\",\"X102\",\"X103\",\"X104\",\"X105\",\"X106\",\"X107\",\"X108\",\"X109\",\"X110\",\"X111\",\"X112\",\"X113\",\"X114\",\"X115\",\"X116\",\"X117\",\"X118\",\"X119\",\"X120\",\"X121\",\"X122\",\"X123\",\"X124\",\"X125\",\"X126\",\"X127\",\"X128\",\"X129\",\"X130\",\"X131\",\"X132\",\"X133\",\"X134\",\"X135\",\"X136\",\"X137\",\"X138\",\"X139\",\"X140\",\"X141\",\"X142\",\"X143\",\"X144\",\"X145\",\"X146\",\"X147\",\"X148\",\"X149\",\"X150\",\"X151\",\"X152\",\"X153\",\"X154\",\"X155\",\"X156\",\"X157\",\"X158\",\"X159\",\"X160\",\"X161\",\"X162\",\"X163\",\"X164\",\"X165\",\"X166\",\"X167\",\"X168\",\"X169\",\"X170\",\"X171\",\"X172\",\"X173\",\"X174\",\"X175\",\"X176\",\"X177\",\"X178\"]\n","# model = load_model(\"Epilepsy.h5\")\n","model = torch.load(\"EEG_torch.pt\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YtYBhyvNNJPZ","executionInfo":{"status":"ok","timestamp":1613495272540,"user_tz":-330,"elapsed":99486,"user":{"displayName":"Srini Sriram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7y0thGEYPYKNwAFoAjrpt6mEJosxCscvoLAx1pg=s64","userId":"08361603766535905230"}},"outputId":"8603eab9-c723-4300-f305-574f6eca2f99"},"source":["arr = [[473.6328125, 260.7421875, 245.60546875, -260.7421875, 0.0], [-1000.0, -1000.0, -1000.0, -803.7109375, 0.0], [-284.1796875, -674.8046875, -862.79296875, 243.1640625, 0.0], [-920.41015625, 967.7734375, 476.07421875, -1000.0, 0.0], [-937.98828125, 682.12890625, 644.53125, -560.05859375, 0.0], [-423.828125, -874.0234375, -530.2734375, -943.84765625, 0.0], [-447.265625, -1000.0, -1000.0, 639.16015625, 0.0], [995.1171875, 165.52734375, -156.25, -954.58984375, 0.0], [-825.1953125, -821.77734375, 860.83984375, -1000.0, 0.0], [67.87109375, -154.296875, -126.46484375, 407.2265625, 0.0], [-797.36328125, -1000.0, -1000.0, -827.63671875, 0.0], [661.1328125, -222.65625, -230.95703125, -174.31640625, 0.0]]\n","\n","arr = pd.DataFrame(arr)\n","arr_1 = list(arr[0])\n","arr_1"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[473.6328125,\n"," -1000.0,\n"," -284.1796875,\n"," -920.41015625,\n"," -937.98828125,\n"," -423.828125,\n"," -447.265625,\n"," 995.1171875,\n"," -825.1953125,\n"," 67.87109375,\n"," -797.36328125,\n"," 661.1328125]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jv0iKrwG0mWF","executionInfo":{"status":"ok","timestamp":1613495641973,"user_tz":-330,"elapsed":880,"user":{"displayName":"Srini Sriram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7y0thGEYPYKNwAFoAjrpt6mEJosxCscvoLAx1pg=s64","userId":"08361603766535905230"}},"outputId":"c2f5f0a1-0603-466c-d411-99c1bb6db7b1"},"source":["arr = [[473.6328125, 260.7421875, 245.60546875, -260.7421875, 0.0], [-1000.0, -1000.0, -1000.0, -803.7109375, 0.0], [-284.1796875, -674.8046875, -862.79296875, 243.1640625, 0.0], [-920.41015625, 967.7734375, 476.07421875, -1000.0, 0.0], [-937.98828125, 682.12890625, 644.53125, -560.05859375, 0.0], [-423.828125, -874.0234375, -530.2734375, -943.84765625, 0.0], [-447.265625, -1000.0, -1000.0, 639.16015625, 0.0], [995.1171875, 165.52734375, -156.25, -954.58984375, 0.0], [-825.1953125, -821.77734375, 860.83984375, -1000.0, 0.0], [67.87109375, -154.296875, -126.46484375, 407.2265625, 0.0], [-797.36328125, -1000.0, -1000.0, -827.63671875, 0.0], [661.1328125, -222.65625, -230.95703125, -174.31640625, 0.0]]\n","new_arr = pd.DataFrame(arr)\n","combine = [existing, new_arr]\n","existing = pd.concat(combine).reset_index(drop=True)\n","print(len(existing))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["198\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4B-_yIw51XK4"},"source":["row = existing[0:num_of_data]\n","row = row[channel_idx]\n","row = pd.DataFrame(row)\n","row = row.T"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":129},"id":"6IbS4XUn5_5a","executionInfo":{"status":"ok","timestamp":1613496984325,"user_tz":-330,"elapsed":884,"user":{"displayName":"Srini Sriram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7y0thGEYPYKNwAFoAjrpt6mEJosxCscvoLAx1pg=s64","userId":"08361603766535905230"}},"outputId":"e77cd494-17b1-4303-e97d-a52d2604d4b0"},"source":["row.columns = index\n","row"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>X1</th>\n","      <th>X2</th>\n","      <th>X3</th>\n","      <th>X4</th>\n","      <th>X5</th>\n","      <th>X6</th>\n","      <th>X7</th>\n","      <th>X8</th>\n","      <th>X9</th>\n","      <th>X10</th>\n","      <th>X11</th>\n","      <th>X12</th>\n","      <th>X13</th>\n","      <th>X14</th>\n","      <th>X15</th>\n","      <th>X16</th>\n","      <th>X17</th>\n","      <th>X18</th>\n","      <th>X19</th>\n","      <th>X20</th>\n","      <th>X21</th>\n","      <th>X22</th>\n","      <th>X23</th>\n","      <th>X24</th>\n","      <th>X25</th>\n","      <th>X26</th>\n","      <th>X27</th>\n","      <th>X28</th>\n","      <th>X29</th>\n","      <th>X30</th>\n","      <th>X31</th>\n","      <th>X32</th>\n","      <th>X33</th>\n","      <th>X34</th>\n","      <th>X35</th>\n","      <th>X36</th>\n","      <th>X37</th>\n","      <th>X38</th>\n","      <th>X39</th>\n","      <th>X40</th>\n","      <th>...</th>\n","      <th>X139</th>\n","      <th>X140</th>\n","      <th>X141</th>\n","      <th>X142</th>\n","      <th>X143</th>\n","      <th>X144</th>\n","      <th>X145</th>\n","      <th>X146</th>\n","      <th>X147</th>\n","      <th>X148</th>\n","      <th>X149</th>\n","      <th>X150</th>\n","      <th>X151</th>\n","      <th>X152</th>\n","      <th>X153</th>\n","      <th>X154</th>\n","      <th>X155</th>\n","      <th>X156</th>\n","      <th>X157</th>\n","      <th>X158</th>\n","      <th>X159</th>\n","      <th>X160</th>\n","      <th>X161</th>\n","      <th>X162</th>\n","      <th>X163</th>\n","      <th>X164</th>\n","      <th>X165</th>\n","      <th>X166</th>\n","      <th>X167</th>\n","      <th>X168</th>\n","      <th>X169</th>\n","      <th>X170</th>\n","      <th>X171</th>\n","      <th>X172</th>\n","      <th>X173</th>\n","      <th>X174</th>\n","      <th>X175</th>\n","      <th>X176</th>\n","      <th>X177</th>\n","      <th>X178</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-447.265625</td>\n","      <td>995.117188</td>\n","      <td>-825.195312</td>\n","      <td>67.871094</td>\n","      <td>-797.363281</td>\n","      <td>661.132812</td>\n","      <td>473.632812</td>\n","      <td>-1000.0</td>\n","      <td>-284.179688</td>\n","      <td>-920.410156</td>\n","      <td>-937.988281</td>\n","      <td>-423.828125</td>\n","      <td>-447.265625</td>\n","      <td>995.117188</td>\n","      <td>-825.195312</td>\n","      <td>67.871094</td>\n","      <td>-797.363281</td>\n","      <td>661.132812</td>\n","      <td>473.632812</td>\n","      <td>-1000.0</td>\n","      <td>-284.179688</td>\n","      <td>-920.410156</td>\n","      <td>-937.988281</td>\n","      <td>-423.828125</td>\n","      <td>-447.265625</td>\n","      <td>995.117188</td>\n","      <td>-825.195312</td>\n","      <td>67.871094</td>\n","      <td>-797.363281</td>\n","      <td>661.132812</td>\n","      <td>473.632812</td>\n","      <td>-1000.0</td>\n","      <td>-284.179688</td>\n","      <td>-920.410156</td>\n","      <td>-937.988281</td>\n","      <td>-423.828125</td>\n","      <td>-447.265625</td>\n","      <td>995.117188</td>\n","      <td>-825.195312</td>\n","      <td>67.871094</td>\n","      <td>...</td>\n","      <td>473.632812</td>\n","      <td>-1000.0</td>\n","      <td>-284.179688</td>\n","      <td>-920.410156</td>\n","      <td>-937.988281</td>\n","      <td>-423.828125</td>\n","      <td>-447.265625</td>\n","      <td>995.117188</td>\n","      <td>-825.195312</td>\n","      <td>67.871094</td>\n","      <td>-797.363281</td>\n","      <td>661.132812</td>\n","      <td>473.632812</td>\n","      <td>-1000.0</td>\n","      <td>-284.179688</td>\n","      <td>-920.410156</td>\n","      <td>-937.988281</td>\n","      <td>-423.828125</td>\n","      <td>-447.265625</td>\n","      <td>995.117188</td>\n","      <td>-825.195312</td>\n","      <td>67.871094</td>\n","      <td>-797.363281</td>\n","      <td>661.132812</td>\n","      <td>473.632812</td>\n","      <td>-1000.0</td>\n","      <td>-284.179688</td>\n","      <td>-920.410156</td>\n","      <td>-937.988281</td>\n","      <td>-423.828125</td>\n","      <td>-447.265625</td>\n","      <td>995.117188</td>\n","      <td>-825.195312</td>\n","      <td>67.871094</td>\n","      <td>-797.363281</td>\n","      <td>661.132812</td>\n","      <td>473.632812</td>\n","      <td>-1000.0</td>\n","      <td>-284.179688</td>\n","      <td>-920.410156</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1 rows × 178 columns</p>\n","</div>"],"text/plain":["           X1          X2          X3  ...    X176        X177        X178\n","0 -447.265625  995.117188 -825.195312  ... -1000.0 -284.179688 -920.410156\n","\n","[1 rows x 178 columns]"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":289},"id":"ycGsCE36NmBK","executionInfo":{"status":"ok","timestamp":1613497796012,"user_tz":300,"elapsed":514,"user":{"displayName":"Abhisar Anand","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWXF-tDLZa8FE4w5YLpEtDFB5FlmkgLzgJ5odopA=s64","userId":"11407336489196125517"}},"outputId":"d32bb00f-d08f-4d7c-d185-35ed57cfd146"},"source":["arr = [[473.6328125, 260.7421875, 245.60546875, -260.7421875, 0.0], [-1000.0, -1000.0, -1000.0, -803.7109375, 0.0], [-284.1796875, -674.8046875, -862.79296875, 243.1640625, 0.0], [-920.41015625, 967.7734375, 476.07421875, -1000.0, 0.0], [-937.98828125, 682.12890625, 644.53125, -560.05859375, 0.0], [-423.828125, -874.0234375, -530.2734375, -943.84765625, 0.0], [-447.265625, -1000.0, -1000.0, 639.16015625, 0.0], [995.1171875, 165.52734375, -156.25, -954.58984375, 0.0], [-825.1953125, -821.77734375, 860.83984375, -1000.0, 0.0], [67.87109375, -154.296875, -126.46484375, 407.2265625, 0.0], [-797.36328125, -1000.0, -1000.0, -827.63671875, 0.0], [661.1328125, -222.65625, -230.95703125, -174.31640625, 0.0]]\n","\n","for i in range(15):\n","    new_arr = pd.DataFrame(arr)\n","    combine = [existing, new_arr]\n","    existing = pd.concat(combine).reset_index(drop=True)\n","    print(len(existing))\n","    if len(existing) >= num_of_data:\n","        row = existing[0:num_of_data]\n","        row = row[channel_idx]\n","        row = pd.DataFrame(row)\n","        row = row.T\n","        row.columns = index\n","        # row = row.values.reshape(-1, 178, 1)\n","        # row = row.values.reshape(178)\n","        existing.drop(existing.index[0:num_of_data], inplace=True)\n","        existing = existing.reset_index(drop=True)\n","        row = row.iloc[0,:]\n","        # print(row.mean())\n","        # print(row.std())\n","        # predictions = model.predict((row[:, ::4] - row.mean())/row.std())\n","        # result = np.argmax(predictions[0]) + 1\n","        # print(result)\n","        row, clas, probs = model.predict(row)\n","        if clas.int() == 1:\n","            print(\"Seizure Detected\")\n","        else:\n","            print(\"No Seizure Detected\")\n","    \n"],"execution_count":125,"outputs":[{"output_type":"stream","text":["58\n","70\n","82\n","94\n","106\n","118\n","130\n","142\n","154\n","166\n","178\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["No Seizure Detected\n","12\n","24\n","36\n","48\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3gq0HutHXTPl"},"source":["import numpy as np\n","import pandas as pd\n","import os\n","from typing import Union, List, Optional\n","from pathlib import Path\n","from pylsl import StreamInlet, resolve_byprop\n","from sklearn.linear_model import LinearRegression\n","from time import time, sleep, strftime, gmtime\n","from .stream import find_muse\n","from .muse import Muse\n","from .constants import LSL_SCAN_TIMEOUT, LSL_EEG_CHUNK, LSL_PPG_CHUNK, LSL_ACC_CHUNK, LSL_GYRO_CHUNK\n","import pandas as pd\n","import numpy as np\n","import fastai\n","import torch\n","\n","# Records a fixed duration of EEG data from an LSL stream into a CSV file\n","\n","def record(\n","    duration: int,\n","    filename=None,\n","    dejitter=False,\n","    data_source=\"EEG\",\n","    continuous: bool = True,\n",") -> None:\n","    chunk_length = LSL_EEG_CHUNK\n","    if data_source == \"PPG\":\n","        chunk_length = LSL_PPG_CHUNK\n","    if data_source == \"ACC\":\n","        chunk_length = LSL_ACC_CHUNK\n","    if data_source == \"GYRO\":\n","        chunk_length = LSL_GYRO_CHUNK\n","\n","    if not filename:\n","        filename = os.path.join(os.getcwd(), \"%s_recording_%s.csv\" %\n","                                (data_source,\n","                                 strftime('%Y-%m-%d-%H.%M.%S', gmtime())))\n","        \n","    channel_idx = 0\n","    num_of_data = 178\n","    existing = pd.DataFrame()\n","    index = [\"X1\",\"X2\",\"X3\",\"X4\",\"X5\",\"X6\",\"X7\",\"X8\",\"X9\",\"X10\",\"X11\",\"X12\",\"X13\",\"X14\",\"X15\",\"X16\",\"X17\",\"X18\",\"X19\",\"X20\",\"X21\",\"X22\",\"X23\",\"X24\",\"X25\",\"X26\",\"X27\",\"X28\",\"X29\",\"X30\",\"X31\",\"X32\",\"X33\",\"X34\",\"X35\",\"X36\",\"X37\",\"X38\",\"X39\",\"X40\",\"X41\",\"X42\",\"X43\",\"X44\",\"X45\",\"X46\",\"X47\",\"X48\",\"X49\",\"X50\",\"X51\",\"X52\",\"X53\",\"X54\",\"X55\",\"X56\",\"X57\",\"X58\",\"X59\",\"X60\",\"X61\",\"X62\",\"X63\",\"X64\",\"X65\",\"X66\",\"X67\",\"X68\",\"X69\",\"X70\",\"X71\",\"X72\",\"X73\",\"X74\",\"X75\",\"X76\",\"X77\",\"X78\",\"X79\",\"X80\",\"X81\",\"X82\",\"X83\",\"X84\",\"X85\",\"X86\",\"X87\",\"X88\",\"X89\",\"X90\",\"X91\",\"X92\",\"X93\",\"X94\",\"X95\",\"X96\",\"X97\",\"X98\",\"X99\",\"X100\",\"X101\",\"X102\",\"X103\",\"X104\",\"X105\",\"X106\",\"X107\",\"X108\",\"X109\",\"X110\",\"X111\",\"X112\",\"X113\",\"X114\",\"X115\",\"X116\",\"X117\",\"X118\",\"X119\",\"X120\",\"X121\",\"X122\",\"X123\",\"X124\",\"X125\",\"X126\",\"X127\",\"X128\",\"X129\",\"X130\",\"X131\",\"X132\",\"X133\",\"X134\",\"X135\",\"X136\",\"X137\",\"X138\",\"X139\",\"X140\",\"X141\",\"X142\",\"X143\",\"X144\",\"X145\",\"X146\",\"X147\",\"X148\",\"X149\",\"X150\",\"X151\",\"X152\",\"X153\",\"X154\",\"X155\",\"X156\",\"X157\",\"X158\",\"X159\",\"X160\",\"X161\",\"X162\",\"X163\",\"X164\",\"X165\",\"X166\",\"X167\",\"X168\",\"X169\",\"X170\",\"X171\",\"X172\",\"X173\",\"X174\",\"X175\",\"X176\",\"X177\",\"X178\"]\n","    model = torch.load(\"EEG_torch.pt\")\n","\n","\n","    print(\"Looking for a %s stream...\" % (data_source))\n","    streams = resolve_byprop('type', data_source, timeout=LSL_SCAN_TIMEOUT)\n","\n","    if len(streams) == 0:\n","        print(\"Can't find %s stream.\" % (data_source))\n","        return\n","\n","    print(\"Started acquiring data.\")\n","    inlet = StreamInlet(streams[0], max_chunklen=chunk_length)\n","    # eeg_time_correction = inlet.time_correction()\n","\n","    print(\"Looking for a Markers stream...\")\n","    marker_streams = resolve_byprop(\n","        'name', 'Markers', timeout=LSL_SCAN_TIMEOUT)\n","\n","    if marker_streams:\n","        inlet_marker = StreamInlet(marker_streams[0])\n","    else:\n","        inlet_marker = False\n","        print(\"Can't find Markers stream.\")\n","\n","    info = inlet.info()\n","    description = info.desc()\n","\n","    Nchan = info.channel_count()\n","\n","    ch = description.child('channels').first_child()\n","    ch_names = [ch.child_value('label')]\n","    for i in range(1, Nchan):\n","        ch = ch.next_sibling()\n","        ch_names.append(ch.child_value('label'))\n","\n","    res = []\n","    timestamps = []\n","    markers = []\n","    t_init = time()\n","    time_correction = inlet.time_correction()\n","    last_written_timestamp = None\n","    print('Start recording at time t=%.3f' % t_init)\n","    print('Time correction: ', time_correction)\n","    while (time() - t_init) < duration:\n","        try:\n","            data, timestamp = inlet.pull_chunk(\n","                timeout=1.0, max_samples=chunk_length)\n","\n","            if timestamp:\n","                # print(\"Data: \" + str(data)) \n","                new_arr = pd.DataFrame(arr)\n","                combine = [existing, new_arr]\n","                existing = pd.concat(combine).reset_index(drop=True)\n","                print(len(existing))\n","                if len(existing) >= num_of_data:\n","                    row = existing[0:num_of_data]\n","                    row = row[channel_idx]\n","                    row = pd.DataFrame(row)\n","                    row = row.T\n","                    row.columns = index\n","                    existing.drop(existing.index[0:num_of_data], inplace=True)\n","                    existing = existing.reset_index(drop=True)\n","                    row = row.iloc[0,:]\n","                    row, clas, probs = model.predict(row)\n","                    if clas.int() == 1:\n","                        print(\"Seizure Detected\")\n","                    else:\n","                        print(\"No Seizure Detected\")\n","\n","                res.append(data)\n","                timestamps.extend(timestamp)\n","                tr = time()\n","            if inlet_marker:\n","                marker, timestamp = inlet_marker.pull_sample(timeout=0.0)\n","                if timestamp:\n","                    markers.append([marker, timestamp])\n","\n","            # Save every 5s\n","            if continuous and (last_written_timestamp is None or last_written_timestamp + 5 < timestamps[-1]):\n","                _save(\n","                    filename,\n","                    res,\n","                    timestamps,\n","                    time_correction,\n","                    dejitter,\n","                    inlet_marker,\n","                    markers,\n","                    ch_names,\n","                    last_written_timestamp=last_written_timestamp,\n","                )\n","                last_written_timestamp = timestamps[-1]\n","\n","        except KeyboardInterrupt:\n","            break\n","\n","    time_correction = inlet.time_correction()\n","    print(\"Time correction: \", time_correction)\n","\n","    _save(\n","        filename,\n","        res,\n","        timestamps,\n","        time_correction,\n","        dejitter,\n","        inlet_marker,\n","        markers,\n","        ch_names,\n","    )\n","\n","    print(\"Done - wrote file: {}\".format(filename))\n","\n","\n","def _save(\n","    filename: Union[str, Path],\n","    res: list,\n","    timestamps: list,\n","    time_correction,\n","    dejitter: bool,\n","    inlet_marker,\n","    markers,\n","    ch_names: List[str],\n","    last_written_timestamp: Optional[float] = None,\n","):\n","    res = np.concatenate(res, axis=0)\n","    timestamps = np.array(timestamps) + time_correction\n","\n","    if dejitter:\n","        y = timestamps\n","        X = np.atleast_2d(np.arange(0, len(y))).T\n","        lr = LinearRegression()\n","        lr.fit(X, y)\n","        timestamps = lr.predict(X)\n","\n","    res = np.c_[timestamps, res]\n","    data = pd.DataFrame(data=res, columns=[\"timestamps\"] + ch_names)\n","\n","    directory = os.path.dirname(filename)\n","    if not os.path.exists(directory):\n","        os.makedirs(directory)\n","\n","    if inlet_marker and markers:\n","        n_markers = len(markers[0][0])\n","        for ii in range(n_markers):\n","            data['Marker%d' % ii] = 0\n","        # process markers:\n","        for marker in markers:\n","            # find index of markers\n","            ix = np.argmin(np.abs(marker[1] - timestamps))\n","            for ii in range(n_markers):\n","                data.loc[ix, \"Marker%d\" % ii] = marker[0][ii]\n","\n","    # If file doesn't exist, create with headers\n","    # If it does exist, just append new rows\n","    if not Path(filename).exists():\n","        # print(\"Saving whole file\")\n","        data.to_csv(filename, float_format='%.3f', index=False)\n","    else:\n","        # print(\"Appending file\")\n","        # truncate already written timestamps\n","        data = data[data['timestamps'] > last_written_timestamp]\n","        data.to_csv(filename, float_format='%.3f', index=False, mode='a', header=False)\n","\n","\n","\n","# Rercord directly from a Muse without the use of LSL\n","\n","\n","def record_direct(duration,\n","                  address,\n","                  filename=None,\n","                  backend='auto',\n","                  interface=None,\n","                  name=None):\n","    if backend == 'bluemuse':\n","        raise (NotImplementedError(\n","            'Direct record not supported with BlueMuse backend. Use record after starting stream instead.'\n","        ))\n","\n","    if not address:\n","        found_muse = find_muse(name, backend)\n","        if not found_muse:\n","            print('Muse could not be found')\n","            return\n","        else:\n","            address = found_muse['address']\n","            name = found_muse['name']\n","        print('Connecting to %s : %s...' % (name if name else 'Muse', address))\n","\n","    if not filename:\n","        filename = os.path.join(\n","            os.getcwd(),\n","            (\"recording_%s.csv\" % strftime(\"%Y-%m-%d-%H.%M.%S\", gmtime())))\n","\n","    eeg_samples = []\n","    timestamps = []\n","\n","    def save_eeg(new_samples, new_timestamps):\n","        eeg_samples.append(new_samples)\n","        timestamps.append(new_timestamps)\n","\n","    muse = Muse(address, save_eeg, backend=backend)\n","    muse.connect()\n","    muse.start()\n","\n","    t_init = time()\n","    print('Start recording at time t=%.3f' % t_init)\n","\n","    while (time() - t_init) < duration:\n","        try:\n","            sleep(1)\n","        except KeyboardInterrupt:\n","            break\n","\n","    muse.stop()\n","    muse.disconnect()\n","\n","    timestamps = np.concatenate(timestamps)\n","    eeg_samples = np.concatenate(eeg_samples, 1).T\n","    recording = pd.DataFrame(\n","        data=eeg_samples, columns=['TP9', 'AF7', 'AF8', 'TP10', 'Right AUX'])\n","\n","    recording['timestamps'] = timestamps\n","\n","    directory = os.path.dirname(filename)\n","    if not os.path.exists(directory):\n","        os.makedirs(directory)\n","\n","    recording.to_csv(filename, float_format='%.3f')\n","    print('Done - wrote file: ' + filename + '.')\n"],"execution_count":null,"outputs":[]}]}